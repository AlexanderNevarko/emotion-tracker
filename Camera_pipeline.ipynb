{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "from scipy.ndimage import zoom\n",
    "from imutils import face_utils\n",
    "from scipy.spatial import distance\n",
    "from time import sleep\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_x = 48\n",
    "shape_y = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('save_files/EmotionDetectionModel.h5')\n",
    "face_haar_cascade = cv2.CascadeClassifier('save_files/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 435 artists>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotion = []\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "while True:\n",
    "    ret,test_img=cap.read()# captures test_img and returns boolean value and captured image\n",
    "    if not ret:\n",
    "        continue\n",
    "    gray_img= cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "    face_index = 0\n",
    "    faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)\n",
    "\n",
    "\n",
    "    for (x,y,w,h) in faces_detected:\n",
    "        cv2.rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=7)\n",
    "        roi_gray=gray_img[y:y+w,x:x+h]#cropping region of interest i.e. face area from  image\n",
    "        roi_gray=cv2.resize(roi_gray,(48,48))\n",
    "        img_pixels = image.img_to_array(roi_gray)\n",
    "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "        img_pixels /= 255\n",
    "\n",
    "        predictions = model.predict(img_pixels)\n",
    "        predictions_result = np.argmax(predictions)\n",
    "        \n",
    "        cv2.putText(test_img, \"Angry : \" + str(round(predictions[0][0],3)),(10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 0)\n",
    "        cv2.putText(test_img, \"Disgust : \" + str(round(predictions[0][1],3)),(10,50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 0)\n",
    "        cv2.putText(test_img, \"Fear : \" + str(round(predictions[0][2],3)),(10,70), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "        cv2.putText(test_img, \"Happy : \" + str(round(predictions[0][3],3)),(10,90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "        cv2.putText(test_img, \"Sad : \" + str(round(predictions[0][4],3)),(10,110), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "        cv2.putText(test_img, \"Surprise : \" + str(round(predictions[0][5],3)),(10,130), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "        cv2.putText(test_img, \"Neutral : \" + str(round(predictions[0][6],3)),(10,150), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "        \n",
    "        # annotate main image with a label\n",
    "        if predictions_result == 0 :\n",
    "            cv2.putText(test_img, \"Angry\",(x,y), cv2.FONT_HERSHEY_SIMPLEX, 2, 155, 10)\n",
    "        elif predictions_result == 1 :\n",
    "            cv2.putText(test_img, \"Disgust\",(x,y), cv2.FONT_HERSHEY_SIMPLEX, 2, 155, 10)\n",
    "        elif predictions_result == 2 :\n",
    "            cv2.putText(test_img, \"Fear\",(x,y), cv2.FONT_HERSHEY_SIMPLEX, 2, 155, 10)\n",
    "        elif predictions_result == 3 :\n",
    "            cv2.putText(test_img, \"Happy\",(x,y), cv2.FONT_HERSHEY_SIMPLEX, 2, 155, 10)\n",
    "        elif predictions_result == 4 :\n",
    "            cv2.putText(test_img, \"Sad\",(x,y), cv2.FONT_HERSHEY_SIMPLEX, 2, 155, 10)\n",
    "        elif predictions_result == 5 :\n",
    "            cv2.putText(test_img, \"Surprise\",(x,y), cv2.FONT_HERSHEY_SIMPLEX, 2, 155, 10)\n",
    "        else :\n",
    "            cv2.putText(test_img, \"Neutral\",(x,y), cv2.FONT_HERSHEY_SIMPLEX, 2, 155, 10)\n",
    "                         \n",
    "        face_index += 1\n",
    "        \n",
    "        emotion.append(predictions_result)\n",
    "        xs.append(i)\n",
    "        ys.append(predictions_result)\n",
    "        \n",
    "        #line1, = ax.plot(i, predictions_result, 'b-') \n",
    "        #line1.set_ydata(predictions_result)\n",
    "        #fig.canvas.draw()\n",
    "            \n",
    "        #print(predictions_result)\n",
    "        \n",
    "        i = i + 1\n",
    "        \n",
    "        #find max indexed array\n",
    "        #max_index = np.argmax(predictionss[0])\n",
    "\n",
    "        #emotions = ('angry', 'happy', 'sad', 'surprise', 'neutral')\n",
    "        #predicted_emotion = emotions[max_index]\n",
    "\n",
    "        #cv2.putText(test_img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "    resized_img = cv2.resize(test_img, (1000, 700))\n",
    "    cv2.imshow('Facial emotion analysis ',resized_img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows\n",
    "plt.bar(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
