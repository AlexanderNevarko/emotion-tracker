{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "from scipy.ndimage import zoom\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "from scipy.spatial import distance\n",
    "from time import sleep\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_x = 48\n",
    "shape_y = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('EmotionDetectionModel.h5')\n",
    "face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 1983 artists>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAN/UlEQVR4nO3cfYwcdR3H8c/HHqBgEbGraYBzwQcSYiKtF9SgJKLRQhV8ioEoomIuJmAgavQMidH/UKNRo9FURVFRfIJIaFCMisZE0btSoKUgBY9YqfTAGPAhYvHrHzPXbtd9mL3uzH6171eyud3Z3+587rdzn87O7tQRIQBAXk+YdAAAwGAUNQAkR1EDQHIUNQAkR1EDQHJTdTzpmjVrot1u1/HUAPB/aWFh4aGIaPW6r5aibrfbmp+fr+OpAeD/ku37+93HoQ8ASI6iBoDkKGoASI6iBoDkKGoASI6iBoDkKhW17WNsf8/2XbZ32H5x3cEAAIWq36P+tKQfRsQbbR8u6cgaMwEAOgwtattHSzpD0tskKSIek/RYvbEAAMuqHPo4SdKSpK/YvtX2l2wf1T3I9qztedvzS0tLYw9aRXtu8wE/+90/7nV2X3plGWXddeTMZtj8DJvXQY/tfo5hGapk7c4x7PkP9jWs+rsN+x3r0m/dw+ao3+2q8zjo9ijr7rV9Vf3bXcnf9MGqUtRTktZL+nxErJP0N0lz3YMiYlNEzETETKvV83R1AMAKVCnqXZJ2RcQt5e3vqShuAEADhhZ1RPxJ0h9sn1wuermkO2tNBQDYp+q3Pt4t6eryGx/3SXp7fZEAAJ0qFXVEbJU0U3MWAEAPnJkIAMlR1ACQHEUNAMlR1ACQHEUNAMlR1ACQHEUNAMlR1ACQHEUNAMlR1ACQHEUNAMlR1ACQHEUNAMlR1ACQHEUNAMlR1ACQHEUNAMlR1ACQHEUNAMlR1ACQHEUNAMlR1ACQHEUNAMlR1ACQHEUNAMlNVRlke1HSo5Iel7Q3ImbqDAUA2K9SUZdeFhEP1ZYEANAThz4AILmqRR2SbrK9YHu21wDbs7bnbc8vLS2NLyGARrXnNve83f2z8/7lS/eyfrerrntYpn6PGXV8dlWL+vSIWC/pLEkX2z6je0BEbIqImYiYabVaYw0JAIeySkUdEQ+UP/dIuk7SaXWGAgDsN7SobR9le/XydUmvlLSt7mAAgEKVb308Q9J1tpfHfzMiflhrKgDAPkOLOiLuk/T8BrIAAHrg63kAkBxFDQDJUdQAkBxFDQDJUdQAkBxFDQDJUdQAkBxFDQDJUdQAkBxFDQDJUdQAkBxFDQDJUdQAkBxFDQDJUdQAkBxFDQDJUdQAkBxFDQDJUdQAkBxFDQDJUdQAkBxFDQDJUdQAkBxFDQDJUdQAkBxFDQDJVS5q26ts32r7hjoDAQAONMoe9aWSdtQVBADQW6Witn28pI2SvlRvHABAt6mK4z4l6f2SVvcbYHtW0qwkTU9PrzhQe27z0DGLV2ys/FyLV2zc97PX8qZ1Z+qXZfn2oN+1+/eqU6+5Wsm6h2UedP9yhs4svZb1e5y0sszDrGQ7GrRNDss4yvqGje21LfbLOG7DXrNR1t1rm6iynnGoe/uSKuxR2361pD0RsTBoXERsioiZiJhptVpjCwgAh7oqhz5Ol3SO7UVJ10g60/Y3ak0FANhnaFFHxAcj4viIaEs6T9JPI+IttScDAEjie9QAkF7VDxMlSRFxs6Sba0kCAOiJPWoASI6iBoDkKGoASI6iBoDkKGoASI6iBoDkKGoASI6iBoDkKGoASI6iBoDkKGoASI6iBoDkKGoASI6iBoDkKGoASI6iBoDkKGoASI6iBoDkKGoASI6iBoDkKGoASI6iBoDkKGoASI6iBoDkKGoASG5oUdt+ou3f2L7N9nbbH2kiGACgMFVhzD8lnRkRf7V9mKRf2r4xIn5dczYAgCoUdUSEpL+WNw8rL1FnKADAflX2qGV7laQFSc+W9LmIuKXHmFlJs5I0PT09zoyoSXtusxav2HjAz1EfX0XnOjLqnocq48e97oNd5zgzIZ9KHyZGxOMRcaqk4yWdZvt5PcZsioiZiJhptVrjzgkAh6yRvvUREX+RdLOkDbWkAQD8lyrf+mjZPqa8/iRJr5B0V93BAACFKseo10q6qjxO/QRJ34mIG+qNBQBYVuVbH7dLWtdAFgBAD5yZCADJUdQAkBxFDQDJUdQAkBxFDQDJUdQAkBxFDQDJUdQAkBxFDQDJUdQAkBxFDQDJUdQAkBxFDQDJUdQAkBxFDQDJUdQAkBxFDQDJUdQAkBxFDQDJUdQAkBxFDQDJUdQAkBxFDQDJUdQAkBxFDQDJUdQAkNzQorZ9gu2f2d5he7vtS5sIBgAoTFUYs1fSeyNii+3VkhZs/zgi7qw5GwBAFfaoI2J3RGwprz8qaYek4+oOBgAoVNmj3sd2W9I6Sbf0uG9W0qwkTU9PjyEa8L+tPbe55/LFKzY2nCSffnOTWXtu88Reu8ofJtp+sqTvS7osIh7pvj8iNkXETETMtFqtcWYEgENapaK2fZiKkr46Iq6tNxIAoFOVb31Y0pcl7YiIT9YfCQDQqcoe9emSLpB0pu2t5eXsmnMBAEpDP0yMiF9KcgNZAAA9cGYiACRHUQNAchQ1ACRHUQNAchQ1ACRHUQNAchQ1ACRHUQNAchQ1ACRHUQNAchQ1ACRHUQNAchQ1ACRHUQNAchQ1ACRHUQNAchQ1ACRHUQNAchQ1ACRHUQNAchQ1ACRHUQNAchQ1ACRHUQNAchQ1ACQ3tKhtX2l7j+1tTQQCAByoyh71VyVtqDkHAKCPoUUdEb+Q9OcGsgAAehjbMWrbs7bnbc8vLS2N62kB4JA3tqKOiE0RMRMRM61Wa1xPCwCHPL71AQDJUdQAkFyVr+d9S9KvJJ1se5fti+qPBQBYNjVsQESc30QQAEBvHPoAgOQoagBIjqIGgOQoagBIjqIGgOQoagBIjqIGgOQoagBIjqIGgOQoagBIjqIGgOQoagBIjqIGgOQoagBIjqIGgOQoagBIjqIGgOQoagBIjqIGgOQoagBIjqIGgOQoagBIjqIGgOQoagBIjqIGgOQoagBIrlJR295g+27bO23P1R0KALDf0KK2vUrS5ySdJekUSefbPqXuYACAQpU96tMk7YyI+yLiMUnXSDq33lgAgGWOiMED7DdK2hAR7yxvXyDphRFxSde4WUmz5c2TJd29wkxrJD20wsfWKWsuKW82co0uazZyjW7UbM+MiFavO6YqPNg9lv1Xu0fEJkmbRgjVe2X2fETMHOzzjFvWXFLebOQaXdZs5BrdOLNVOfSxS9IJHbePl/TAOFYOABiuSlH/VtJzbJ9o+3BJ50m6vt5YAIBlQw99RMRe25dI+pGkVZKujIjtNWY66MMnNcmaS8qbjVyjy5qNXKMbW7ahHyYCACaLMxMBIDmKGgCSS1PUkzxN3fYJtn9me4ft7bYvLZd/2PYfbW8tL2d3POaDZda7bb+q5nyLtu8oM8yXy461/WPb95Q/n9pkNtsnd8zLVtuP2L5sUnNm+0rbe2xv61g28hzZfkE51zttf8Z2r6+nHmyuj9u+y/bttq+zfUy5vG37Hx1z94WGc4382o0714Bs3+7ItWh7a7m8yTnr1xP1b2cRMfGLig8p75V0kqTDJd0m6ZQG179W0vry+mpJv1NxuvyHJb2vx/hTyoxHSDqxzL6qxnyLktZ0LfuYpLny+pykj04iW8fr9ydJz5zUnEk6Q9J6SdsOZo4k/UbSi1WcP3CjpLNqyPVKSVPl9Y925Gp3jut6niZyjfzajTtXv2xd939C0ocmMGf9eqL27SzLHvVET1OPiN0RsaW8/qikHZKOG/CQcyVdExH/jIjfS9qp4ndo0rmSriqvXyXptRPM9nJJ90bE/QPG1JorIn4h6c891ll5jmyvlXR0RPwqir+mr3U8Zmy5IuKmiNhb3vy1inMT+moq1wCNzdewbOWe55skfWvQc9Q0Z/16ovbtLEtRHyfpDx23d2lwUdbGdlvSOkm3lIsuKd+iXtnxlqbpvCHpJtsLLk7Vl6RnRMRuqdiAJD19Qtmk4rv1nX84GeZMGn2OjiuvN5nxHSr2qJadaPtW2z+3/dJyWZO5RnntJjFfL5X0YETc07Gs8Tnr6onat7MsRV3pNPXaQ9hPlvR9SZdFxCOSPi/pWZJOlbRbxVsuqfm8p0fEehX/g+HFts8YMLbRbC5OgjpH0nfLRVnmbJB+WZqeu8sl7ZV0dblot6TpiFgn6T2Svmn76AZzjfraTeI1PV8H7hQ0Pmc9eqLv0D4ZRs6Wpagnfpq67cNUTP7VEXGtJEXEgxHxeET8W9IXtf+teqN5I+KB8uceSdeVOR4s30Itv83bM4lsKv7x2BIRD5YZU8xZadQ52qUDD0PUltH2hZJeLenN5dtflW+RHy6vL6g4pvncpnKt4LVrbL4kyfaUpNdL+nZH5kbnrFdPqIHtLEtRT/Q09fK415cl7YiIT3YsX9sx7HWSlj+Fvl7SebaPsH2ipOeo+HCgjmxH2V69fF3FB1HbygwXlsMulPSDprOVDtjDyTBnHUaao/Jt66O2X1RuE2/teMzY2N4g6QOSzomIv3csb7n4/99l+6Qy130N5hrptWsqV4dXSLorIvYdNmhyzvr1hJrYzg7mU9BxXiSdreJT1HslXd7wul+i4q3H7ZK2lpezJX1d0h3l8uslre14zOVl1rs1hk+6B2Q7ScUnx7dJ2r48N5KeJuknku4pfx47gWxHSnpY0lM6lk1kzlT8Y7Fb0r9U7LFctJI5kjSjoqDulfRZlWfvjjnXThXHLpe3tS+UY99Qvsa3Sdoi6TUN5xr5tRt3rn7ZyuVflfSurrFNzlm/nqh9O+MUcgBILsuhDwBAHxQ1ACRHUQNAchQ1ACRHUQNAchQ1ACRHUQNAcv8BxtO+JG7nQfMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotion = []\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "while True:\n",
    "    ret,test_img=cap.read()# captures test_img and returns boolean value and captured image\n",
    "    if not ret:\n",
    "        continue\n",
    "    gray_img= cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "    face_index = 0\n",
    "    faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)\n",
    "\n",
    "\n",
    "    for (x,y,w,h) in faces_detected:\n",
    "        cv2.rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=7)\n",
    "        roi_gray=gray_img[y:y+w,x:x+h]#cropping region of interest i.e. face area from  image\n",
    "        roi_gray=cv2.resize(roi_gray,(48,48))\n",
    "        img_pixels = image.img_to_array(roi_gray)\n",
    "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "        img_pixels /= 255\n",
    "\n",
    "        predictions = model.predict(img_pixels)\n",
    "        predictions_result = np.argmax(predictions)\n",
    "        \n",
    "        cv2.putText(test_img, \"Angry : \" + str(round(predictions[0][0],3)),(10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 0)\n",
    "        cv2.putText(test_img, \"Disgust : \" + str(round(predictions[0][1],3)),(10,50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 0)\n",
    "        cv2.putText(test_img, \"Fear : \" + str(round(predictions[0][2],3)),(10,70), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "        cv2.putText(test_img, \"Happy : \" + str(round(predictions[0][3],3)),(10,90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "        cv2.putText(test_img, \"Sad : \" + str(round(predictions[0][4],3)),(10,110), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "        cv2.putText(test_img, \"Surprise : \" + str(round(predictions[0][5],3)),(10,130), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "        cv2.putText(test_img, \"Neutral : \" + str(round(predictions[0][6],3)),(10,150), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 155, 1)\n",
    "        \n",
    "        # annotate main image with a label\n",
    "        if predictions_result == 0 :\n",
    "            cv2.putText(test_img, \"Angry\",(x,y), cv2.FONT_HERSHEY_SIMPLEX, 2, 155, 10)\n",
    "        elif predictions_result == 1 :\n",
    "            cv2.putText(test_img, \"Disgust\",(x,y), cv2.FONT_HERSHEY_SIMPLEX, 2, 155, 10)\n",
    "        elif predictions_result == 2 :\n",
    "            cv2.putText(test_img, \"Fear\",(x,y), cv2.FONT_HERSHEY_SIMPLEX, 2, 155, 10)\n",
    "        elif predictions_result == 3 :\n",
    "            cv2.putText(test_img, \"Happy\",(x,y), cv2.FONT_HERSHEY_SIMPLEX, 2, 155, 10)\n",
    "        elif predictions_result == 4 :\n",
    "            cv2.putText(test_img, \"Sad\",(x,y), cv2.FONT_HERSHEY_SIMPLEX, 2, 155, 10)\n",
    "        elif predictions_result == 5 :\n",
    "            cv2.putText(test_img, \"Surprise\",(x,y), cv2.FONT_HERSHEY_SIMPLEX, 2, 155, 10)\n",
    "        else :\n",
    "            cv2.putText(test_img, \"Neutral\",(x,y), cv2.FONT_HERSHEY_SIMPLEX, 2, 155, 10)\n",
    "                         \n",
    "        face_index += 1\n",
    "        \n",
    "        emotion.append(predictions_result)\n",
    "        xs.append(i)\n",
    "        ys.append(predictions_result)\n",
    "        \n",
    "        #line1, = ax.plot(i, predictions_result, 'b-') \n",
    "        #line1.set_ydata(predictions_result)\n",
    "        #fig.canvas.draw()\n",
    "            \n",
    "        #print(predictions_result)\n",
    "        \n",
    "        i = i + 1\n",
    "        \n",
    "        #find max indexed array\n",
    "        #max_index = np.argmax(predictionss[0])\n",
    "\n",
    "        #emotions = ('angry', 'happy', 'sad', 'surprise', 'neutral')\n",
    "        #predicted_emotion = emotions[max_index]\n",
    "\n",
    "        #cv2.putText(test_img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "    resized_img = cv2.resize(test_img, (1000, 700))\n",
    "    cv2.imshow('Facial emotion analysis ',resized_img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows\n",
    "plt.bar(xs, ys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
